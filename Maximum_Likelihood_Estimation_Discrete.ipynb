{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Maximum Likelihood Estimation_Discrete.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQn9gw8xO7f2HG702dYprR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeonJun-IN/probability_for_machine_learning/blob/main/Maximum_Likelihood_Estimation_Discrete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqKT7sYZseRI"
      },
      "source": [
        "# MLE(Maximum Likelihood Estimation)\n",
        "## Bernoulli Distribution\n",
        "#### Parameter Estimation\n",
        "> $PMF \\space \\space of \\space \\space Bern(p): \\space \\space  P(X=x) = p^x (1-p)^{1-x}$\n",
        ">\n",
        "> $Likelihood \\space \\space function \\space \\space of \\space \\space Bern(p): \\space \\space P(x_1, x_2,..., x_n | p) = \\prod_{i=1}^{n}p^{x_i} (1-p)^{1-x_i} = L(p)$\n",
        ">\n",
        "> $LL(p) = \\log {\\prod_{i=1}^{n}p^{x_i} (1-p)^{1- x_i}} = \\sum_{i=1}^{n}\\log{p^{x_i} (1-p)^{1- x_i}}$\n",
        ">\n",
        "> $= \\log p \\sum_{i=1}^{n}x_i + \\log (1-p)\\sum_{i=1}^{n}(1-x_i)$\n",
        ">\n",
        "> $\\frac{dLL}{dp} = \\frac{1}{p}\\sum_{i=1}^{n}x_i - \\frac{1}{1-p}\\sum_{i=1}^{n}(1-x_i)=\\frac{1}{p}\\sum_{i=1}^{n}x_i - \\frac{n}{1-p} +\\frac{1}{1-p}\\sum_{i=1}^{n}x_i =0 $\n",
        ">\n",
        "> $\\frac{1}{p(1-p)}\\sum_{i=1}^n x_i = \\frac{n}{1-p}$\n",
        ">\n",
        "> $\\hat{p} = \\frac{1}{n}\\sum_{i=1}^{n}x_i = \\bar{X}$\n",
        "#### Check unbiasedness\n",
        "> $E(\\hat{p})=E(\\frac{1}{n}\\sum_{i=1}^{n}x_i) = \\frac{1}{n}E(x_1 + x_2 + ... + x_n) =  E(x_1)$ by Linearity\n",
        ">\n",
        "> $X \\sim Bern(p)$일 때, $E(X)=p$\n",
        ">\n",
        "> $E(\\hat{p}) = p \\space\\space \\therefore unbiased \\space\\space estimator$\n",
        "\n",
        "\n",
        "## Binomial Distribution\n",
        "#### Parameter Estimation\n",
        "> $PMF \\space \\space of \\space \\space Bin(n, p): \\space \\space  P(X) = {n\\choose k}p^k (1-p)^{n-k}$\n",
        ">\n",
        "> $Likelihood \\space \\space function \\space \\space of \\space \\space Bin(n, p): \\space \\space P(x_1, x_2,..., x_m | p) = \\prod_{i=1}^{m}{n \\choose x_i}p^{x_i} (1-p)^{n- x_i} = L(p)$\n",
        ">\n",
        "> $LL(p) = \\log {\\prod_{i=1}^{m}{n \\choose x_i}p^{x_i} (1-p)^{n- x_i}} = \\sum_{i=1}^{m}\\log{{n \\choose x_i}p^{x_i} (1-p)^{n- x_i}}$\n",
        ">\n",
        "> $= \\sum_{i=1}^{m}\\log{n \\choose x_i}  +\\log p \\sum_{i=1}^{m}x_i + \\log (1-p)\\sum_{i=1}^{m}(n-x_i)$\n",
        ">\n",
        "> $\\frac{dLL}{dp} = \\frac{1}{p}\\sum_{i=1}^{m}x_i - \\frac{1}{1-p}\\sum_{i=1}^{m}(n-x_i)=\\frac{1}{p}\\sum_{i=1}^{m}x_i - \\frac{nm}{1-p}+\\frac{1}{1-p}\\sum_{i=1}^{m}x_i=0$\n",
        ">\n",
        "> $\\frac{1}{p(1-p)}\\sum_{i=1}^m x_i = \\frac{nm}{1-p}$\n",
        ">\n",
        "> $\\hat{p} = \\frac{1}{nm}\\sum_{i=1}^{m}x_i$\n",
        "#### Check unbiasedness\n",
        "> $E(\\hat{p})=E(\\frac{1}{nm}\\sum_{i=1}^{m}x_i) = \\frac{1}{nm}E(x_1 + x_2 + ... + x_m) =  \\frac{1}{n}E(x_1)$ by Linearity\n",
        ">\n",
        "> $X \\sim Bin(n, p)$일 때, $E(X)=np$\n",
        ">\n",
        "> $E(\\hat{p}) = \\frac{1}{n}np = p \\space\\space \\therefore unbiased \\space\\space estimator$\n",
        "\n",
        "## Geometric Distribution\n",
        "#### Paramter Estimation\n",
        "> $PMF \\space \\space of \\space \\space Geom(p): \\space \\space  P(X=x) = (1-p)^{x}p$\n",
        ">\n",
        "> $Likelihood \\space \\space function \\space \\space of \\space \\space Geom(p): \\space \\space P(x_1, x_2,..., x_n | p) = \\prod_{i=1}^{n}(1-p)^{x_i}p = L(p)$\n",
        ">\n",
        "> $LL(p) = \\log{\\prod_{i=1}^{n}(1-p)^{x_i}p} = \\sum_{i=1}^n {(x_i\\log{(1-p)} + \\log{p}}) = \\log{(1-p)}\\sum_{i=1}^n{x_i} + n\\log{p}$\n",
        ">\n",
        "> $\\frac{dLL}{dp}=-\\frac{1}{1-p}\\sum_{i=1}^n{x_i} + \\frac{n}{p}=0$\n",
        ">\n",
        "> $\\frac{1}{p}-1 = \\frac{1}{n}\\sum_{i=1}^n{x_i}$\n",
        ">\n",
        "> $\\frac{1}{p} = 1 + \\frac{1}{n}\\sum_{i=1}^n{x_i} = 1+ \\bar{X}$\n",
        "> \n",
        "> $\\hat{p} = \\frac{1}{1+\\bar{X}}$\n",
        ">\n",
        "> \n",
        "\n",
        "#### Check unbiasedness\n",
        "> $E(\\frac{1}{\\hat{p}}) = E(1 + \\frac{1}{n}\\sum_{i=1}^n{x_i}) = 1 + \\frac{1}{n}E(x_1+x_2+ ... + x_n)=1+E(x_1)$ by Linearity\n",
        ">\n",
        "> $X \\sim Geom(p)$일 때, $E(X)=\\frac{1-p}{p}$\n",
        ">\n",
        "> $E(\\frac{1}{\\hat{p}})=1 + \\frac{1-p}{p} = \\frac{1}{p}\\space\\space \\therefore unbiased \\space\\space estimator$ \n",
        "\n",
        "## Poisson Distribution\n",
        "#### Parameter Estimation\n",
        "> $PMF \\space \\space of \\space \\space Pois(\\lambda): \\space \\space  P(X) = e^{-\\lambda} \\lambda ^k / k!$\n",
        ">\n",
        "> $Likelihood \\space \\space function \\space \\space of \\space \\space Pois(\\lambda): \\space \\space P(x_1, x_2,..., x_n | \\lambda) = \\prod_{i=1}^{n}e^{-\\lambda} \\lambda^{x_i} / x_i! = L(\\lambda)$\n",
        ">\n",
        "> $LL(\\lambda) = \\log {\\prod_{i=1}^{n}e^{-\\lambda} \\lambda^{x_i} / x_i!} = \\sum_{i=1}^{n}{\\log{e^{-\\lambda} \\lambda^{x_i} / x_i!}}= \\sum_{i=1}^{n}[{\\log{e^{-\\lambda}}} + \\log{\\lambda^{x_i}} - \\log{x_i!}]$\n",
        ">\n",
        "> $= -\\lambda n +\\log{\\lambda}\\sum_{i=1}^n {x_i} - \\sum_{i=1}^n{\\log{x_i!}}$\n",
        ">\n",
        "> $\\frac{dLL}{d\\lambda} = -n + \\frac{1}{\\lambda}\\sum_{i=1}^n {x_i}=0$\n",
        ">\n",
        "> $\\lambda = \\frac{1}{n}\\sum_{i=1}^n {x_i}$\n",
        "#### Check unbiasedness\n",
        "> $E(\\hat{\\lambda})=E(\\frac{1}{n}\\sum_{i=1}^n {x_i}) = \\frac{1}{n}E(x_1 + x_2 + ... + x_n) = E(x_1)$ by Linearity\n",
        ">\n",
        "> $X \\sim Pois(\\lambda)$일 때, $E(X)=\\lambda$\n",
        ">\n",
        "> $E(\\hat{\\lambda}) = \\lambda \\space\\space \\therefore unbiased \\space\\space estimator$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L-DvGpNwDRc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}